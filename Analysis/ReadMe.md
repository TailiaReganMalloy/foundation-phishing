# Data documentation for analyses

This document describes the datasets used in the analyses for the project “Improving Online Training to Identify Phishing Emails Generated by Humans and LLMs.” It covers the participant-level results as well as the email stimulus metadata.

## Files and locations

- Participant results (primary analysis input):
	- `Data/ParticipantData.csv`
	- Also available as: `Data/ParticipantData.json`, `.mat`, `.pkl`, `.xlsx`

- Email stimuli metadata (optional join for content-level analyses):
	- `WebsiteDemo/public/csv/Source/data.csv` (human/ham vs phishing labels, sender, subject, body, and feature flags)

Note: Older references to a generic “Data.csv” refer to the participant results now stored as `ParticipantData.*` under `Data/`.

## Participant results schema (row-level)

Each row represents either a participant’s decision on a single email or a message exchanged with the teaching chatbot during that trial. Use `DataType` to distinguish these.

- Identification
	- UserId: participant identifier (string or int)
	- Experiment: study variant (e.g., 1–4)
	- Condition (aka ExperimentCondition): experimental condition label or code (int or string)
	- PhaseValue: task phase label such as preTraining, Training, postTraining
	- PhaseTrial: within-phase trial index (int)
	- ExperimentTrial: overall trial index (int)

- Stimulus
	- EmailId: integer ID of the email shown to the participant
	- EmailType: ground-truth class of the email (phishing or ham)

- Trial outcome (present on decision rows)
	- DataType: type of row; typically "decision" for trial responses and "message" for chat turns
	- Decision: binary decision indicating “phishing” vs “legitimate” selection (see Notes)
	- EmailAction: categorical action chosen (e.g., respond, click link, check sender, check link, delete, report)
	- Confidence: ordinal confidence rating. In the web app this is a 5-point scale; stored as 0–4 (representing 1–5) in some exports.
	- ReactionTime: response latency per decision. Assumed milliseconds (jsPsych default).
	- Correct: 1 if the decision matches EmailType, else 0

- Conversation data (present on message rows)
	- DataType: "message"
	- MessageNum: index of the message within the trial (int)
	- Message: free-text content (participant or chatbot)

- Demographics and questionnaires (attached within-participant across rows)
	- Age, Gender, Education, Country
	- Victim: prior victimization experience (categorical/ordinal)
	- Chatbot: chatbot configuration/selection
	- Consent: boolean/flag for consent
	- Q0–Q5: general questionnaire responses
	- PQ0–PQ5: post-questionnaire responses
	- Rejected: quality/exclusion flag (1 indicates exclusion)

- Derived/per-participant aggregates (computed in figure scripts; may appear in summarization exports)
	- Training Speed: speed metric based on reaching an accuracy threshold during Training
	- Pretraining Accuracy: mean Correct during preTraining
	- Categorization Improvement: postTraining Correct − preTraining Correct
	- AI Generation Perception, AI Perception Accuracy, Baseline Phishing Knowledge
	- Author, Style, Feedback, Selection: experimental manipulations/labels used in some variants

### Important notes and conventions

- Rows with `DataType == "message"` contain conversation turns and do not include final Decision/Correct. Filter to `DataType == "decision"` for trial-level accuracy analyses.
- Confidence uses a 5-level radio selection in the web task; some exports store this as 0–4; map to 1–5 if you prefer human-readable scales.
- ReactionTime is recorded by the client-side task; by convention we treat this as milliseconds (jsPsych default). Convert to seconds if needed.
- Correct is computed by comparing Decision to EmailType (phishing vs ham).
- Exclusions: remove participants with `Rejected == 1` or without `Consent` before confirmatory analyses.

## Email stimuli schema (`WebsiteDemo/public/csv/Source/data.csv`)

Each row describes an email used in the experiment.

- EmailID: integer key (join to Participant `EmailId`)
- Type: phishing or ham (ground truth)
- Sender: sender email string
- Subject: subject line
- Body: textual content (may contain HTML)
- Link: URL present in the email (if any)
- LinkText: anchor/display text associated with Link
- sender_mismatch: 0/1 flag (sender email mismatch)
- request_credentials: 0/1 flag
- subject_suspecious: 0/1 flag (sic; suspicious subject indicators)
- urgent: 0/1 flag (urgency cue)
- offer: 0/1 flag (incentive/offer cue)
- link_mismatch: 0/1 flag (display vs destination mismatch)

## Typical analysis workflow

Python environment: see `Analysis/requirements.txt` for pinned versions (pandas, seaborn, statsmodels, scikit-learn, pyibl, etc.).

Example load and basic checks:

```python
import pandas as pd

results = pd.read_csv('Data/ParticipantData.csv')
stimuli = pd.read_csv('WebsiteDemo/public/csv/Source/data.csv')

# trial-level decisions only
decisions = results[results['DataType'] == 'decision'].copy()

# join on EmailId
decisions = decisions.merge(stimuli.rename(columns={'EmailID':'EmailId'}), on='EmailId', how='left')

# filter participants (consented, not rejected)
decisions = decisions[(decisions['Consent'] == 1) & (decisions['Rejected'] != 1)]

# accuracy by phase
acc_by_phase = decisions.groupby(['UserId','PhaseValue'])['Correct'].mean().reset_index()
print(acc_by_phase.head())
```

Common groupings (see figure scripts in `Analysis/Figures/`):

- Pretraining Accuracy: subset `PhaseValue == 'preTraining'`
- PostTraining Accuracy: subset `PhaseValue == 'postTraining'`
- Categorization Improvement: post − pre by participant
- Training Speed: rolling accuracy threshold during `Training` phase (see `Figure4.py`, `Results.py` for exact logic and thresholds)

## Field reference (quick lookup)

- UserId, Experiment, Condition, PhaseValue, PhaseTrial, ExperimentTrial
- EmailId, EmailType
- DataType, Decision, Confidence, EmailAction, ReactionTime, Correct
- MessageNum, Message
- Age, Gender, Education, Country, Victim, Chatbot, Consent
- Q0–Q5, PQ0–PQ5, Rejected
- Training Speed, Pretraining Accuracy, Categorization Improvement
- AI Generation Perception, AI Perception Accuracy, Baseline Phishing Knowledge
- Author, Style, Feedback, Selection

If you need deeper semantics for any field while replicating a specific figure, consult the corresponding script in `Analysis/Figures/` (e.g., `Figure4.py`, `Figure5.py`, `Results.py`, `Statistics.py`).